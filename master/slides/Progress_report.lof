\select@language {english}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Mesh \relax }}{10}{figure.caption.8}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Example of polynomial fitting with degree 10 on a random dataset \relax }}{13}{figure.caption.9}
\contentsline {figure}{\numberline {4.3}{\ignorespaces A binary tree built for a classification $(1, 2, 3)$ problem from an input space $[-15, 15] \times [-15, 25]$\relax }}{14}{figure.caption.10}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Example of Gaussian Kernel Regression\relax }}{18}{figure.caption.13}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Regression at time $t=T- \Delta t$ \relax }}{24}{figure.caption.16}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Display of the regression step using LSM method (in blue) with different polynomial degrees and display of $Y_{t}\frac {\Delta B_t}{\Delta t}$ with respect to, both with respect to $X_t$ \relax }}{26}{figure.caption.19}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Display of the regression step using mesh method (in blue) and display of $Y_{t}\frac {\Delta B_t}{\Delta t}$ (red) , both with respect to $X_t$\relax }}{27}{figure.caption.22}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Pricing error with number of maximum leafs for different number of samples N\relax }}{30}{figure.caption.26}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Display of the regression step using RF method (in blue) and display of $Y_{t}\frac {\Delta B_t}{\Delta t}$ (red) , both with respect to $X_t$, fixing the number of samples to 10.000 and playing with number of leafs b\relax }}{31}{figure.caption.27}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces Choosing the best vertical split using RSS measure\relax }}{48}{figure.caption.49}
\contentsline {figure}{\numberline {A.2}{\ignorespaces Analysis of number trees in a Random Forest\relax }}{52}{figure.caption.53}
\contentsline {figure}{\numberline {A.3}{\ignorespaces Box plot giving the mean square error given by Random forest with increasing number of leafs\relax }}{53}{figure.caption.54}
\contentsline {figure}{\numberline {A.4}{\ignorespaces Box plot giving the mean square error of regression given by Random forest with increasing number of features\relax }}{54}{figure.caption.56}
\contentsline {figure}{\numberline {A.5}{\ignorespaces First ten most important variables given by Random Forest\relax }}{55}{figure.caption.58}
\contentsline {figure}{\numberline {A.6}{\ignorespaces Variable Importance with 5 correlated features $X_i$,$i \in \{1,\cdots , 5\}$ respectively taking importances 0.3785, 0.1612, 0.1545, 0.2319, 0.0739.\relax }}{56}{figure.caption.59}
\contentsline {figure}{\numberline {A.7}{\ignorespaces Correlation matrix between the features of our housing market data\relax }}{57}{figure.caption.60}
\contentsline {figure}{\numberline {A.8}{\ignorespaces Correlation matrix between the features of our housing market data\relax }}{57}{figure.caption.61}
